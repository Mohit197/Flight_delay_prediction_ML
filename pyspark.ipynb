{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing PySpark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing and Importing All Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "from pyspark.sql.functions import round\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating A Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/17 22:03:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('Flight Predict Project') \\\n",
    "                    .getOrCreate()\n",
    "#Printing the version Of Pyspark installed\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_Predict = spark.read.csv('flights-larger.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing Out the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contain 275000 records.\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| NULL|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|\n",
      "|  3| 28|  1|     B6|   377|LGA|1076| 13.33|     182|   70|\n",
      "|  5| 28|  6|     B6|   904|ORD| 740|  9.58|     130|   47|\n",
      "|  1| 19|  2|     UA|   820|SFO| 679| 12.75|     123|  135|\n",
      "|  8|  5|  5|     US|  2175|LGA| 214|  13.0|      71|  -10|\n",
      "|  5| 27|  5|     AA|  1240|ORD|1197| 14.42|     195|  -11|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Getting The number of records\n",
    "print(\"The dataset contain %d records.\" % flights_Predict.count())\n",
    "# Printing first ten rows of the dataset\n",
    "flights_Predict.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking data Type of each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
     ]
    }
   ],
   "source": [
    "print(flights_Predict.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258289\n"
     ]
    }
   ],
   "source": [
    "# Removing the 'flight' column\n",
    "flights_Predict =  flights_Predict.drop('flight')\n",
    "\n",
    "# Removing records with missing values \n",
    "flights_Predict = flights_Predict.dropna()\n",
    "print(flights_Predict.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Miles to Kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|\n",
      "|  5| 28|  6|     B6|ORD|  9.58|     130|   47|1191.0|    1|\n",
      "|  1| 19|  2|     UA|SFO| 12.75|     123|  135|1093.0|    1|\n",
      "|  8|  5|  5|     US|LGA|  13.0|      71|  -10| 344.0|    0|\n",
      "|  5| 27|  5|     AA|ORD| 14.42|     195|  -11|1926.0|    0|\n",
      "|  8| 20|  6|     B6|JFK| 14.67|     198|   20|1902.0|    1|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Conversion From 'mile' to 'km' \n",
    "flights_Predict_km = flights_Predict.withColumn('km', round(flights_Predict.mile * 1.60934, 0)) \\\n",
    "                    .drop('mile')\n",
    "\n",
    "# Generating a 'label' column to indicate the delay status of a flight.\n",
    "flights_Predict_km = flights_Predict_km.withColumn('label', (flights_Predict_km.delay >= 15).cast('integer'))\n",
    "\n",
    "# Printing the ten records\n",
    "flights_Predict_km.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|        2.0|    0.0|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|        2.0|    0.0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|        4.0|    2.0|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|        3.0|    5.0|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|        4.0|    3.0|\n",
      "|  5| 28|  6|     B6|ORD|  9.58|     130|   47|1191.0|    1|        4.0|    0.0|\n",
      "|  1| 19|  2|     UA|SFO| 12.75|     123|  135|1093.0|    1|        0.0|    1.0|\n",
      "|  8|  5|  5|     US|LGA|  13.0|      71|  -10| 344.0|    0|        6.0|    3.0|\n",
      "|  5| 27|  5|     AA|ORD| 14.42|     195|  -11|1926.0|    0|        1.0|    0.0|\n",
      "|  8| 20|  6|     B6|JFK| 14.67|     198|   20|1902.0|    1|        4.0|    2.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate an indexer to identify categories and create a new column with numeric index values\n",
    "flights_indexed = StringIndexer(inputCol='carrier', outputCol='carrier_idx').fit(flights_Predict_km).transform(flights_Predict_km)\n",
    "\n",
    "# Extend the process to the 'org' column\n",
    "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)\n",
    "flights_indexed.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |delay|\n",
      "+-----------------------------------------+-----+\n",
      "|[10.0,10.0,1.0,2.0,0.0,253.0,8.18,51.0]  |27   |\n",
      "|[11.0,22.0,1.0,2.0,0.0,1188.0,7.17,127.0]|-19  |\n",
      "|[2.0,14.0,5.0,4.0,2.0,3618.0,21.17,365.0]|60   |\n",
      "|[5.0,25.0,3.0,3.0,5.0,621.0,12.92,85.0]  |22   |\n",
      "|[3.0,28.0,1.0,4.0,3.0,1732.0,13.33,182.0]|70   |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate an assembler object\n",
    "assembler = VectorAssembler(inputCols=['mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration'], outputCol='features')\n",
    "\n",
    "# Combine predictor columns\n",
    "flights_assembled = assembler.transform(flights_indexed)\n",
    "\n",
    "# Examine the resulting column\n",
    "flights_assembled.select('features', 'delay').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7998753334443202\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset into training and testing sets with an 80:20 ratio\n",
    "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Verify that the training set constitutes approximately 80% of the records\n",
    "training_ratio = flights_train.count() / flights_assembled.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0    |1.0       |[0.32147118544723785,0.6785288145527621]|\n",
      "|1    |0.0       |[0.5346618613525546,0.4653381386474454] |\n",
      "|1    |0.0       |[0.5346618613525546,0.4653381386474454] |\n",
      "|1    |1.0       |[0.32147118544723785,0.6785288145527621]|\n",
      "|1    |1.0       |[0.32147118544723785,0.6785288145527621]|\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DT classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(flights_train)\n",
    "# Create predictions on test data\n",
    "prediction = tree_model.transform(flights_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9251|\n",
      "|    0|       0.0|16079|\n",
      "|    1|       1.0|16764|\n",
      "|    0|       1.0| 9596|\n",
      "+-----+----------+-----+\n",
      "\n",
      "0.6353840201199459\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/17 22:16:10 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9471|\n",
      "|    0|       0.0|14934|\n",
      "|    1|       1.0|16544|\n",
      "|    0|       1.0|10741|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a classifier object and train on training data\n",
    "logistic = LogisticRegression().fit(flights_train)\n",
    "# Create predictions for the testing data and show confusion matrix\n",
    "prediction = logistic.transform(flights_test)\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.64\n",
      "recall    = 0.64\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}'.format(precision, recall))\n",
    "\n",
    "# Find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "# Find AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: \"areaUnderROC\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.557109692396982\n",
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0|13343|\n",
      "|    0|       0.0|16125|\n",
      "|    1|       1.0|12672|\n",
      "|    0|       1.0| 9550|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['mon', 'dom', 'dow',\n",
    "'carrier_idx', 'org_idx', 'km', 'depart', 'duration'], outputCol=\"features_NB2\")\n",
    "flights_train = assembler.transform(flights_train)\n",
    "\n",
    "# Create a Naive Bayes classifier\n",
    "naive_bayes = NaiveBayes(smoothing=1.0, modelType=\"multinomial\", labelCol=\"label\", featuresCol=\"features_NB2\")\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "naive_bayes_model = naive_bayes.fit(flights_train)\n",
    "\n",
    "# Assuming 'flights_test' is your test dataset\n",
    "flights_test = assembler.transform(flights_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = naive_bayes_model.transform(flights_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Show confusion matrix\n",
    "predictions.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6344360611336816\n",
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0    |1.0       |[0.35090104797685606,0.6490989520231438]|\n",
      "|1    |1.0       |[0.49068345563733534,0.5093165443626646]|\n",
      "|1    |1.0       |[0.49068345563733534,0.5093165443626646]|\n",
      "|1    |1.0       |[0.3548775052248382,0.6451224947751618] |\n",
      "|1    |1.0       |[0.3548775052248382,0.6451224947751618] |\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# Assuming 'flights_train' has columns 'feature1', 'feature2', ..., and 'label'\n",
    "assembler = VectorAssembler(inputCols=['mon', 'dom', 'dow',\n",
    "'carrier_idx', 'org_idx', 'km', 'depart', 'duration'], outputCol=\"features_RF\")\n",
    "flights_train = assembler.transform(flights_train)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "random_forest = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features_RF\", numTrees=10)\n",
    "\n",
    "# Train the Random Forest model\n",
    "random_forest_model = random_forest.fit(flights_train)\n",
    "\n",
    "# Assuming 'flights_test' is your test dataset\n",
    "flights_test = assembler.transform(flights_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = random_forest_model.transform(flights_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Show predictions including label, predicted label, and probability\n",
    "predictions.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 7432|\n",
      "|    0|       0.0|14211|\n",
      "|    1|       1.0|18583|\n",
      "|    0|       1.0|11464|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6344360611336816\n",
      "Precision: 0.6184644057643026\n",
      "Recall: 0.7143186623102057\n",
      "F1 Score: 0.6629445970532625\n"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "predictions.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = predictions.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = predictions.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = predictions.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = predictions.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Precision measures the accuracy of the positive predictions\n",
    "precision = TP / (TP + FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Recall (Sensitivity) measures the proportion of actual positives correctly predicted\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# F1 Score is the harmonic mean of precision and recall\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(f\"F1 Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.603869220352099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 225:======================================>                  (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9028|\n",
      "|    0|       0.0|14227|\n",
      "|    1|       1.0|16987|\n",
      "|    0|       1.0|11448|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# Assuming 'flights_train' has columns 'feature1', 'feature2', ..., and 'label'\n",
    "assembler = VectorAssembler(inputCols=['mon', 'dom', 'dow',\n",
    "'carrier_idx', 'org_idx', 'km', 'depart', 'duration'], outputCol=\"features_SVM\")\n",
    "flights_train = assembler.transform(flights_train)\n",
    "\n",
    "# Create a Linear SVM classifier\n",
    "svm = LinearSVC(maxIter=10, regParam=0.1, labelCol=\"label\", featuresCol=\"features_SVM\")\n",
    "\n",
    "# Wrap the SVM with OneVsRest for multiclass classification\n",
    "ovr = OneVsRest(classifier=svm, labelCol=\"label\", featuresCol=\"features_SVM\")\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = ovr.fit(flights_train)\n",
    "\n",
    "# Assuming 'flights_test' is your test dataset\n",
    "flights_test = assembler.transform(flights_test)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = svm_model.transform(flights_test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Show confusion matrix\n",
    "predictions.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shutting The spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
